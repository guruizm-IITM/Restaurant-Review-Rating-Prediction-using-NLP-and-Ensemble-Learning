# Sentiment Classification using TF-IDF and Logistic Regression

## ğŸ“˜ Project Overview

This project focuses on **emotion detection from text data** using a
**TF-IDF Vectorizer** and **Logistic Regression** model. The goal is to
accurately classify emotional expressions into predefined categories
such as *joy, sadness, anger, fear, surprise, and love*. The model is
trained on preprocessed text, vectorized using TF-IDF, and fine-tuned
for multi-class classification.

------------------------------------------------------------------------

## ğŸ¯ Objectives

-   Preprocess and clean raw text data for emotion classification.
-   Apply TF-IDF vectorization to transform text into numerical
    features.
-   Train and evaluate a Logistic Regression model for multi-class
    classification.
-   Ensure predictions align with original emotion labels.
-   Build a reproducible, clean pipeline suitable for deployment or
    further experimentation.

------------------------------------------------------------------------

## ğŸ§  Model Workflow

1.  **Data Cleaning** -- Handle missing values, remove extra spaces, and
    sanitize column names.\
2.  **Text Preprocessing** -- Tokenization, lowercasing, and optional
    stopword removal.\
3.  **Feature Extraction** -- Convert text into numerical features using
    TF-IDF.\
4.  **Model Training** -- Train a Logistic Regression classifier on the
    transformed dataset.\
5.  **Prediction & Evaluation** -- Predict emotions on test data and map
    them back to original labels.

------------------------------------------------------------------------

## âš™ï¸ Tech Stack

-   **Python 3.9+**
-   **scikit-learn**
-   **pandas**
-   **numpy**
-   **nltk** (for preprocessing, if needed)

------------------------------------------------------------------------

## ğŸ“Š Evaluation Metrics

-   **Accuracy**
-   **Precision**
-   **Recall**
-   **F1-Score**
-   **Confusion Matrix** for detailed analysis

------------------------------------------------------------------------

## ğŸ—ï¸ Repository Structure

    emotion-detection-tfidf-logreg/
    â”‚
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ train.csv
    â”‚   â”œâ”€â”€ test.csv
    â”‚
    â”œâ”€â”€ notebooks/
    â”‚   â”œâ”€â”€ eda_and_preprocessing.ipynb
    â”‚   â”œâ”€â”€ model_training.ipynb
    â”‚
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ preprocess.py
    â”‚   â”œâ”€â”€ train_model.py
    â”‚   â”œâ”€â”€ predict.py
    â”‚
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ tfidf_vectorizer.pkl
    â”‚   â”œâ”€â”€ logistic_regression_model.pkl
    â”‚
    â”œâ”€â”€ README.md
    â””â”€â”€ requirements.txt

------------------------------------------------------------------------

## ğŸš€ How to Run

### 1ï¸âƒ£ Clone the Repository

``` bash
git clone https://github.com/<your-username>/emotion-detection-tfidf-logreg.git
cd emotion-detection-tfidf-logreg
```

### 2ï¸âƒ£ Install Dependencies

``` bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run the Pipeline

``` bash
python src/train_model.py
```

### 4ï¸âƒ£ Predict Emotions

``` bash
python src/predict.py --input "I am feeling great today!"
```

------------------------------------------------------------------------

## ğŸ“ˆ Results

The model demonstrates strong accuracy and generalization capability
across diverse emotion classes. TF-IDF with Logistic Regression provides
a solid baseline for emotion detection tasks.

------------------------------------------------------------------------

## ğŸ’¡ Future Improvements

-   Experiment with **transformer-based embeddings** (e.g., BERT).\
-   Add **cross-validation** and **hyperparameter tuning**.\
-   Extend to **multi-label emotion detection**.\
-   Deploy via **Flask** or **FastAPI** for real-time inference.

------------------------------------------------------------------------

## ğŸ‘¨â€ğŸ’» Author

**Abhishek Guru**\
Data Science & AI, IIT Madras\
Passionate about NLP, Kaggle, and applied machine learning.

------------------------------------------------------------------------

## ğŸ·ï¸ License

This project is licensed under the **MIT License**.
